{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGwqhPmJVIzb"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oNTYk8g3nDfG"
      },
      "outputs": [],
      "source": [
        "# Initialize environment variables/constants (for Google Colab)\n",
        "# import os\n",
        "# from google.colab import userdata\n",
        "\n",
        "# os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")\n",
        "\n",
        "\n",
        "# Initialize environment variables/constants (for VS Code)\n",
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aR-V4U66oE4T"
      },
      "outputs": [],
      "source": [
        "# Install langchain groq\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install -U langchain-groq\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pD5fVpWSnULv"
      },
      "outputs": [],
      "source": [
        "# Instantiate an LLM\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "model = init_chat_model(\n",
        "    model=\"deepseek-r1-distill-llama-70b\",\n",
        "    model_provider=\"groq\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvtdvgtVVM_I"
      },
      "source": [
        "## Clues Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "zeo_bTg_nuCn"
      },
      "outputs": [],
      "source": [
        "# Write the prompts\n",
        "import json\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "You are the game master of a game called \"Disinformer\", which is similar to the \"message relay\" game. Below is the description of how the game works:\n",
        "```\n",
        "In this cooperative game, players use communication and teamwork to uncover the original prompt over multiple rounds of clues. Along the way, they must contend with a disruptive “Disinformer,” varying player interpretations, and time limits.\n",
        "\n",
        "There will be a minimum of 3 players and maximum of 10 players:\n",
        "- Regular players (a.k.a. the netizens): The job is to solve clues and discover the original prompt\n",
        "- at most 2 misinformed players: Has the same job as the regular players. However, this player is unknowingly being given vague/ambiguous clues.\n",
        "- at most 2 disinformer players: The job is to solve clues and discover prompt to persuade other players from clue.\n",
        "\n",
        "There will be 2 rounds in each game.\n",
        "- In the first round, the players will be given clues to guess a general category/term (e.g. \"movie\", \"song\", \"novel\", etc)\n",
        "- In the second round, the players will be given clues to guess a more specific thing (e.g. \"The Dark Knight (2008)\", \"The Hitchhiker's Guide to the Galaxy (Novel)\", \"Space Oddity - David Bowie (1969)\", etc) which is related to the general category in the previous round.\n",
        "\n",
        "In each round, there will be 3 type of clues for each player:\n",
        "- Informed: Not-so-easy but unambiguous clues.\n",
        "- Misinformed: Ambiguous/vague clues that may potentially make them think an entirely different guess (intended for the misinformed player).\n",
        "- Fake: Clues that point to one of the wrong answers.\n",
        "\n",
        "Additionally, in each round, the players will be given 10 minutes to discuss their guess. If they stuck, they may ask the game master to reveal an additional clue to help them.\n",
        "```\n",
        "\n",
        "As a game master, given a category and a thing (e.g. Movie: The Dark Knight (2008)), for each round, generate:\n",
        "- 9 informed clues for the regular players. Make the clues to be as distinct as possible.\n",
        "- 1 extra informed clue for a backup.\n",
        "- 2 misinformed clues.\n",
        "- 2 fake clues\n",
        "- Also, the answer choices for that round (3 choices)\n",
        "\n",
        "For round 2, make sure it is subtle enough. For example, when generating clues for a movie:\n",
        "- No direct names.\n",
        "- No title references.\n",
        "- Focus on plot nuances, secondary characters, or themes instead of iconic moments.\n",
        "\n",
        "For each of the clues you generated, make sure it is between 15-20 words.\n",
        "\n",
        "Then, you also need to provide 3 instructions to help the disinformer.\n",
        "Based on the set of informed and misinformed clues you have came up with, using the Polarisation strategy, generate 3 instructions to help the disinformer player.\n",
        "\n",
        "However, there are some restrictions that you must follow:\n",
        "- You must not mention the answer choices except for the true answer.\n",
        "- The disinformer is not aware which clues are the misinformed ones. So, avoid giving advice that aims to leverage the misinformed clues\n",
        "\n",
        "After this, we will provide you with a pair consisting of the general category and the more specific thing in the following JSON format: `<general category> - <specific thing>`\n",
        "{\n",
        "  \"round_1\": \"<general category>\",\n",
        "  \"round_2\": \"<specific thing>\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "output_format = \"\"\"\n",
        "Write the ouput using the following JSON format:\n",
        "[\n",
        "  {\n",
        "    \"answer\": \"<Answer of round 1>\",\n",
        "    \"informed_clues\": [<9 clues for the regular players>],\n",
        "    \"misinformed_clues\": [<2 misinformed clues>],\n",
        "    \"extra_clues\": [<1 extra informed clue for a backup>],\n",
        "    \"fake_clues\": [<2 fake clues>],\n",
        "    \"choices\": [<3 answer choices including the true answer>],\n",
        "    \"disinformer_instructions\": [<3 instructions for the disinformer>]\n",
        "  },\n",
        "  {\n",
        "    \"answer\": \"<Answer of round 2>\",\n",
        "    \"informed_clues\": [<9 clues for the regular players>],\n",
        "    \"misinformed_clues\": [<2 misinformed clues>],\n",
        "    \"extra_clues\": [<1 extra informed clue for a backup>],\n",
        "    \"fake_clues\": [<2 fake clues>],\n",
        "    \"choices\": [<3 answer choices including the true answer>],\n",
        "    \"disinformer_instructions\": [<3 instructions for the disinformer>]\n",
        "  },\n",
        "]\n",
        "\"\"\"\n",
        "\n",
        "one_shot_example = \"\"\"\n",
        "Below is one example of a query:\n",
        "\n",
        "Q: {\n",
        "  \"round_1\": \"Song\",\n",
        "  \"round_2\": \"Love Story - Taylor Swift\"\n",
        "}\n",
        "A: [\n",
        "  {\n",
        "    \"answer\": \"song\",\n",
        "    \"informed_clues\": [\n",
        "      \"Used to mark an emotional high point of a movie or personal moment.\",\n",
        "      \"It swiftly conveys snapshots you’d replay in your mind instead of reading them on a page.\",\n",
        "      ...\n",
        "    ],\n",
        "    \"misinformed_clues\": [\n",
        "      \"It’s something you might browse over your morning coffee\",\n",
        "      \"\"\n",
        "    ],\n",
        "    \"extra_clues\": [\n",
        "      \"It moves you through peaks and valleys of emotion using only rhythm and tone.\"\n",
        "    ],\n",
        "    \"fake_clues\": [\n",
        "      \"\",\n",
        "      \"\"\n",
        "    ],\n",
        "    \"choices\": [\n",
        "      \"book\",\n",
        "      \"short film\",\n",
        "      \"song\"\n",
        "    ],\n",
        "    \"disinformer_instructions\": [\n",
        "      \"\",\n",
        "      \"\",\n",
        "      \"\"\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"answer\": \"Love Story by Taylor Swift\",\n",
        "    \"informed_clues\": [\n",
        "      \"Draws on imagery of timeless romance, referencing feuding families rather than actual feuding houses.\",\n",
        "      \"Uses a whisper-soft bridge to heighten tension before a triumphant key change.\",\n",
        "      ...\n",
        "    ],\n",
        "    \"misinformed_clues\": [\n",
        "      \"It’s about sneaking out at dawn to crash a royal wedding you weren’t invited to.\"\n",
        "    ],\n",
        "    \"extra_clues\": [\n",
        "      \"Evokes a nostalgic flashback of meeting someone young, then leaps into a narrative confession.\"\n",
        "    ],\n",
        "    \"fake_clues\": [\n",
        "      \"\",\n",
        "      \"\"\n",
        "    ],\n",
        "    \"choices\": [\n",
        "      \"A Thousand Years – Christina Perri\",\n",
        "      \"Love Story - Taylor Swift\",\n",
        "      \"I Will Always Love You - Whitney Houston\"\n",
        "    ],\n",
        "    \"disinformer_instructions\": [\n",
        "      \"\",\n",
        "      \"\",\n",
        "      \"\"\n",
        "    ]\n",
        "  }\n",
        "]\n",
        "\"\"\"\n",
        "\n",
        "user_prompt = json.dumps(\n",
        "    {\n",
        "      \"round_1\": \"Movie\",\n",
        "      \"round_2\": \"Star Wars Episode I: The Phantom Menace\"\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "A30l2KPXpnx1"
      },
      "outputs": [],
      "source": [
        "# Construct the prompt and invoke the model\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(system_prompt + output_format + one_shot_example),\n",
        "    HumanMessage(user_prompt),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEhE77_CqBWB",
        "outputId": "9be72816-b786-4bde-ed6b-97f6f6787752"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<think>\n",
            "Alright, I need to help the user by generating the Disinformer game setup for their query. The user provided a JSON input with \"Movie\" as round 1 and \"Star Wars Episode I: The Phantom Menace\" as round 2. My task is to create a JSON output that includes informed clues, misinformed clues, fake clues, answer choices, and disinformer instructions for both rounds.\n",
            "\n",
            "First, I'll tackle round 1, which is about the general category \"Movie.\" I need to generate 9 informed clues that are distinct. These clues should be clear and point towards movies without being too obvious. For example, I can mention aspects like storytelling, visuals, or common elements in movies. I also need to create 2 misinformed clues that are vague, possibly leading players away from the correct answer. Two fake clues that point to wrong categories like \"book\" or \"video game\" would be good. The answer choices should include the correct answer and two plausible distractors.\n",
            "\n",
            "Moving on to round 2, the specific thing is \"Star Wars Episode I: The Phantom Menace.\" Here, the clues need to be more subtle, focusing on plot nuances, secondary characters, or themes rather than direct references. I'll avoid mentioning specific names like \"Anakin\" or \"Obi-Wan\" but instead describe their roles or scenes. Again, I'll create 9 informed clues, 2 misinformed ones, 2 fake clues, and 3 answer choices including the correct movie.\n",
            "\n",
            "For the disinformer instructions, I need to provide 3 strategies that a disinformer can use, leveraging the Polarisation strategy. This means creating division or reinforcing incorrect ideas without referencing the answer choices. I'll suggest ways to confuse the group by introducing doubt or alternative interpretations based on the clues provided.\n",
            "\n",
            "I also need to ensure that all clues are between 15-20 words and that I don't mention the answer choices except for the true answer. Additionally, the disinformer instructions shouldn't target the misinformed clues since the disinformer isn't aware of them.\n",
            "\n",
            "I'll structure each round's JSON as per the example, making sure to include all required fields. I'll start with round 1, then round 2, ensuring each has the correct number of clues and choices. Finally, I'll review everything to make sure it fits the word count and doesn't violate any restrictions.\n",
            "</think>\n",
            "\n",
            "Here is the JSON output for your query:\n",
            "\n",
            "```json\n",
            "[\n",
            "  {\n",
            "    \"answer\": \"Movie\",\n",
            "    \"informed_clues\": [\n",
            "      \"A medium that tells stories through moving images and sound.\",\n",
            "      \"Often features fictional or non-fictional narratives.\",\n",
            "      \"Can be watched in theaters, at home, or on devices.\",\n",
            "      \"May include dialogue, music, and special effects.\",\n",
            "      \"Can be categorized into genres like action, comedy, or drama.\",\n",
            "      \"Usually lasts between 1 to 3 hours in length.\",\n",
            "      \"Can be based on books, true events, or original ideas.\",\n",
            "      \"Involves actors performing roles to convey the story.\",\n",
            "      \"Is a popular form of entertainment worldwide.\"\n",
            "    ],\n",
            "    \"misinformed_clues\": [\n",
            "      \"It’s something you might find in a library or bookstore.\",\n",
            "      \"It’s a form of art that doesn’t involve moving images.\"\n",
            "    ],\n",
            "    \"extra_clues\": [\n",
            "      \"It can make you laugh, cry, or feel excited through its storytelling.\"\n",
            "    ],\n",
            "    \"fake_clues\": [\n",
            "      \"It’s a type of video game.\",\n",
            "      \"It’s a form of written literature.\"\n",
            "    ],\n",
            "    \"choices\": [\n",
            "      \"Book\",\n",
            "      \"Video Game\",\n",
            "      \"Movie\"\n",
            "    ],\n",
            "    \"disinformer_instructions\": [\n",
            "      \"Encourage the group to focus on the written word and storytelling.\",\n",
            "      \"Suggest that the answer might be something you can hold in your hand.\",\n",
            "      \"Emphasize the importance of dialogue in the medium.\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"answer\": \"Star Wars Episode I: The Phantom Menace\",\n",
            "    \"informed_clues\": [\n",
            "      \"Features a young version of a famous character in a lightsaber duel.\",\n",
            "      \"Involves a trade federation and a blockade of a planet.\",\n",
            "      \"Introduces a queen who plays a key role in galactic politics.\",\n",
            "      \"Includes a podracing sequence that determines the fate of a character.\",\n",
            "      \"A wise mentor figure gives guidance to the young protagonist.\",\n",
            "      \"The story revolves around the discovery of a chosen one.\",\n",
            "      \"A character’s fate is tied to a prophecy about balance in the Force.\",\n",
            "      \"A council of leaders discusses the growing threat to peace.\",\n",
            "      \"A young character is a slave who shows great potential.\"\n",
            "    ],\n",
            "    \"misinformed_clues\": [\n",
            "      \"It’s about a group of rebels fighting against an evil empire.\",\n",
            "      \"The story focuses on a secret agent on a mission to save the world.\"\n",
            "    ],\n",
            "    \"extra_clues\": [\n",
            "      \"The film introduces a character who becomes a central figure in a galactic conflict.\"\n",
            "    ],\n",
            "    \"fake_clues\": [\n",
            "      \"It’s the first film in a popular sci-fi series.\",\n",
            "      \"It’s about a group of space explorers on a distant planet.\"\n",
            "    ],\n",
            "    \"choices\": [\n",
            "      \"Star Wars Episode IV: A New Hope\",\n",
            "      \"Star Wars Episode I: The Phantom Menace\",\n",
            "      \"Star Trek: The Next Generation\"\n",
            "    ],\n",
            "    \"disinformer_instructions\": [\n",
            "      \"Suggest that the story is about a group of rebels fighting against an empire.\",\n",
            "      \"Emphasize the importance of a secret agent’s mission.\",\n",
            "      \"Encourage the group to focus on space exploration themes.\"\n",
            "    ]\n",
            "  }\n",
            "]\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "# Invoke the model\n",
        "response = model.invoke(messages)\n",
        "\n",
        "# Print the response\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gowLe0zqqVot",
        "outputId": "25a2e9a5-6e5b-480d-e7cd-4c25cc2b9568"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_tokens': 1364, 'output_tokens': 1181, 'total_tokens': 2545}\n"
          ]
        }
      ],
      "source": [
        "# Print the usage metadata\n",
        "print(response.usage_metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CNLDkykK-FU"
      },
      "source": [
        "# Game Clue Analysis Matrix\n",
        "\n",
        "## 1. Length Compliance\n",
        "| Status | Criteria |\n",
        "|--------|----------|\n",
        "| ✅ PASS | All clues 15-20 words |\n",
        "| ❌ FAIL | Any clues outside range |\n",
        "\n",
        "**Outliers:** ___/13 clues failed\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Quality Scores (Rate 1-5)\n",
        "\n",
        "### Informed Clues: ___/5\n",
        "- [ ] Different angles (plot, characters, themes, technical, cultural)\n",
        "- [ ] Reasonable connection to correct answer\n",
        "- [ ] Nothing gives away too much\n",
        "\n",
        "### Misinformed Clues: ___/5\n",
        "- [ ] Could point to 2+ different answers\n",
        "- [ ] Vague but not nonsensical\n",
        "- [ ] Not obviously wrong\n",
        "\n",
        "### Fake Clues: ___/5\n",
        "- [ ] Clearly point to wrong answer choices\n",
        "- [ ] Believable enough to fool players\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Diversity Check\n",
        "- [ ] **PASS** - Informed clues cover different aspects\n",
        "- [ ] **FAIL** - Found duplicates: ________________\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Difficulty Rating\n",
        "| Score | Assessment |\n",
        "|-------|------------|\n",
        "| 1-2 | Too Easy |\n",
        "| 3 | Just Right |\n",
        "| 4-5 | Too Hard |\n",
        "\n",
        "**Rating:** ___/5\n",
        "\n",
        "---\n",
        "\n",
        "## Overall Assessment\n",
        "**Pass/Fail:** ______  \n",
        "**Main Issues:** ______________________  \n",
        "**Notes:** ____________________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "JYyUqexMP36L"
      },
      "outputs": [],
      "source": [
        "# List of different topics to test\n",
        "test_topics = [\n",
        "    {\"round_1\": \"Movie\", \"round_2\": \"Star Wars Episode I: The Phantom Menace\"},\n",
        "    {\"round_1\": \"Song\", \"round_2\": \"Bohemian Rhapsody - Queen\"},\n",
        "    {\"round_1\": \"Book\", \"round_2\": \"Harry Potter and the Sorcerer's Stone\"},\n",
        "    {\"round_1\": \"TV Show\", \"round_2\": \"Breaking Bad\"},\n",
        "    {\"round_1\": \"Video Game\", \"round_2\": \"The Legend of Zelda: Breath of the Wild\"},\n",
        "    {\"round_1\": \"Food\", \"round_2\": \"Pizza Margherita\"},\n",
        "    {\"round_1\": \"Animal\", \"round_2\": \"African Elephant\"},\n",
        "    {\"round_1\": \"Sport\", \"round_2\": \"Tennis\"},\n",
        "    {\"round_1\": \"Country\", \"round_2\": \"Japan\"},\n",
        "    {\"round_1\": \"Historical Event\", \"round_2\": \"Moon Landing 1969\"}\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfPgMxCaJrl1"
      },
      "source": [
        "### Manual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "3tUvM920BaA-"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import csv\n",
        "import pandas as pd\n",
        "from time import sleep\n",
        "from datetime import datetime\n",
        "from langchain_core.messages import HumanMessage, SystemMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ZGIYGFrwK-Ly"
      },
      "outputs": [],
      "source": [
        "def extract_json_from_response(content):\n",
        "    \"\"\"Extract JSON from model response using multiple fallback methods\"\"\"\n",
        "    # Clean escaped quotes\n",
        "    content = content.replace('\\\\\"', '\"')\n",
        "\n",
        "    # Method 1: Direct parse\n",
        "    try:\n",
        "        return json.loads(content)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Method 2: Extract from code blocks\n",
        "    match = re.search(r\"```(?:json)?\\s*(.*?)\\s*```\", content, re.DOTALL)\n",
        "    if match:\n",
        "        try:\n",
        "            return json.loads(match.group(1))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # Method 3: Find incomplete array and fix\n",
        "    match = re.search(r\"(\\[.*)\", content, re.DOTALL)\n",
        "    if match:\n",
        "        json_text = match.group(1).rstrip()\n",
        "        if not json_text.endswith(']'):\n",
        "            json_text = json_text.rstrip(',') + ']'\n",
        "        try:\n",
        "            return json.loads(json_text)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "P3wJUwXKBdwP"
      },
      "outputs": [],
      "source": [
        "def process_game_data(game_data, topic, run_number):\n",
        "    \"\"\"Process valid game data into rows\"\"\"\n",
        "    rows = []\n",
        "    for i, round_data in enumerate(game_data, start=1):\n",
        "        answer = round_data.get(\"answer\", \"\")\n",
        "        choices = \", \".join(round_data.get(\"choices\", []))\n",
        "\n",
        "        for clue_type in [\"informed_clues\", \"misinformed_clues\", \"fake_clues\", \"extra_clues\"]:\n",
        "            for j, clue in enumerate(round_data.get(clue_type, []), start=1):\n",
        "                word_count = len(clue.split())\n",
        "                rows.append({\n",
        "                    \"test_run\": run_number,\n",
        "                    \"topic_category\": topic['round_1'],\n",
        "                    \"topic_specific\": topic['round_2'],\n",
        "                    \"round\": i,\n",
        "                    \"answer\": answer,\n",
        "                    \"choices\": choices,\n",
        "                    \"clue_type\": clue_type.replace(\"_clues\", \"\"),\n",
        "                    \"clue_number\": j,\n",
        "                    \"clue_text\": clue,\n",
        "                    \"word_count\": word_count,\n",
        "                    \"length_ok\": \"YES\" if 15 <= word_count <= 20 else \"NO\",\n",
        "                    \"manual_score / comment\": \"\"\n",
        "                })\n",
        "    return rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChsBIcQsBhDM",
        "outputId": "67436162-39dd-4b17-f5d5-682e3eadaf96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running test 1/10: Movie - Star Wars Episode I: The Phantom Menace\n",
            "✅ Test 1 completed successfully\n",
            "Running test 2/10: Song - Bohemian Rhapsody - Queen\n",
            "✅ Test 2 completed successfully\n",
            "Running test 3/10: Book - Harry Potter and the Sorcerer's Stone\n",
            "✅ Test 3 completed successfully\n",
            "Running test 4/10: TV Show - Breaking Bad\n",
            "✅ Test 4 completed successfully\n",
            "Running test 5/10: Video Game - The Legend of Zelda: Breath of the Wild\n",
            "✅ Test 5 completed successfully\n",
            "Running test 6/10: Food - Pizza Margherita\n",
            "✅ Test 6 completed successfully\n",
            "Running test 7/10: Animal - African Elephant\n",
            "✅ Test 7 completed successfully\n",
            "Running test 8/10: Sport - Tennis\n",
            "✅ Test 8 completed successfully\n",
            "Running test 9/10: Country - Japan\n",
            "✅ Test 9 completed successfully\n",
            "Running test 10/10: Historical Event - Moon Landing 1969\n",
            "✅ Test 10 completed successfully\n"
          ]
        }
      ],
      "source": [
        "# Main execution\n",
        "all_rows = []\n",
        "\n",
        "for run_number, topic in enumerate(test_topics, 1):\n",
        "    print(f\"Running test {run_number}/{len(test_topics)}: {topic['round_1']} - {topic['round_2']}\")\n",
        "\n",
        "    messages = [\n",
        "        SystemMessage(system_prompt + output_format + one_shot_example),\n",
        "        HumanMessage(json.dumps(topic)),\n",
        "    ]\n",
        "\n",
        "    response = model.invoke(messages)\n",
        "    clean_content = re.sub(r\"<think>.*?</think>\", \"\", response.content, flags=re.DOTALL).strip()\n",
        "    game_data = extract_json_from_response(clean_content)\n",
        "\n",
        "    if game_data:\n",
        "        try:\n",
        "            all_rows.extend(process_game_data(game_data, topic, run_number))\n",
        "            print(f\"✅ Test {run_number} completed successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error processing data for test {run_number}: {e}\")\n",
        "    else:\n",
        "        print(f\"❌ No valid JSON found for test {run_number}\")\n",
        "        print(\"RAW:\", clean_content[:200])\n",
        "\n",
        "    sleep(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6HdR9_0Ht1y",
        "outputId": "d5285434-a3c2-4fab-9c88-672d0a3d7c29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ CSV saved: 10_rounds_clues_analysis.csv\n",
            "Total rows generated: 280\n"
          ]
        }
      ],
      "source": [
        "# Save to CSV\n",
        "with open(\"10_rounds_clues_analysis.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    if all_rows:\n",
        "        writer = csv.DictWriter(f, fieldnames=all_rows[0].keys())\n",
        "        writer.writeheader()\n",
        "        writer.writerows(all_rows)\n",
        "        print(f\"✅ CSV saved: 10_rounds_clues_analysis.csv\")\n",
        "\n",
        "print(f\"Total rows generated: {len(all_rows)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A0fc3WdZymW"
      },
      "source": [
        "## LLM analysis (llama)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ixZR4gtyhwU-"
      },
      "outputs": [],
      "source": [
        "analysis_model = init_chat_model(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    model_provider=\"groq\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "_OurpVJ2h9eD"
      },
      "outputs": [],
      "source": [
        "def analyze_round_with_llm(round_data, analysis_model):\n",
        "    \"\"\"Analyze a single round using LLM\"\"\"\n",
        "\n",
        "    # Count words for each clue type\n",
        "    word_counts = {}\n",
        "    length_issues = []\n",
        "\n",
        "    for clue_type in [\"informed_clues\", \"misinformed_clues\", \"fake_clues\", \"extra_clues\"]:\n",
        "        clues = round_data.get(clue_type, [])\n",
        "        word_counts[clue_type] = []\n",
        "\n",
        "        for i, clue in enumerate(clues, 1):\n",
        "            word_count = len(clue.split())\n",
        "            word_counts[clue_type].append(word_count)\n",
        "\n",
        "            if not (15 <= word_count <= 20):\n",
        "                length_issues.append(f\"{clue_type} #{i}: {word_count} words\")\n",
        "\n",
        "    # Create word count summary\n",
        "    word_count_summary = f\"\"\"\n",
        "WORD COUNT ANALYSIS:\n",
        "- Informed clues: {word_counts.get('informed_clues', [])}\n",
        "- Misinformed clues: {word_counts.get('misinformed_clues', [])}\n",
        "- Fake clues: {word_counts.get('fake_clues', [])}\n",
        "- Extra clues: {word_counts.get('extra_clues', [])}\n",
        "\n",
        "LENGTH ISSUES (should be 15-20 words):\n",
        "{'; '.join(length_issues) if length_issues else 'All clues meet length requirements'}\n",
        "\"\"\"\n",
        "\n",
        "    analysis_prompt = f\"\"\"\n",
        "You are evaluating clues for a deduction game. Analyze BOTH word count compliance AND content quality.\n",
        "\n",
        "{word_count_summary}\n",
        "\n",
        "ROUND DATA:\n",
        "{json.dumps(round_data, indent=2)}\n",
        "\n",
        "CRITICAL REQUIREMENTS:\n",
        "1. LENGTH COMPLIANCE: Each clue should be 15-20 words (see analysis above)\n",
        "2. ANSWER CONTAMINATION: Check if ANY clue contains the answer word\n",
        "3. SPECIFICITY: Are clues specific enough to distinguish from similar items?\n",
        "4. CLUE REFERENCES: Use specific clue numbers when noting issues\n",
        "5. DETAILED REASONING: Explain WHY you gave each score\n",
        "\n",
        "CLUE TYPE REQUIREMENTS:\n",
        "- **INFORMED CLUES**: Must relate to actual answer and be distinct/specific (avoid generic descriptions)\n",
        "- **MISINFORMED CLUES**: Must be related to actual answer BUT vague enough to apply to multiple choices (create productive doubt)\n",
        "- **FAKE CLUES**: Must clearly point to the OTHER answer choices, NOT the correct answer (effective misdirection)\n",
        "\n",
        "SCORING SCALE (MANDATORY):\n",
        "Rate based on how well each clue type fulfills its specific purpose:\n",
        "- informed_quality: Rate 1-5 (How well do they point to correct answer specifically?)\n",
        "- misinformed_quality: Rate 1-5 (Do they create ambiguity while staying answer-related?)\n",
        "- fake_quality: Rate 1-5 (Do they clearly misdirect to wrong answer choices?)\n",
        "- difficulty: Rate 1-5 (1=too easy, 2=easy, 3=just right, 4=hard, 5=too hard)\n",
        "\n",
        "Return ONLY this JSON format:\n",
        "{{\n",
        "  \"length_compliance_score\": number (1-5),\n",
        "  \"length_issues_found\": [\"list of specific length problems\"],\n",
        "  \"informed_quality\": number (1-5),\n",
        "  \"informed_notes\": \"detailed analysis with specific clue numbers\",\n",
        "  \"misinformed_quality\": number (1-5),\n",
        "  \"misinformed_notes\": \"detailed analysis of ambiguity effectiveness\",\n",
        "  \"fake_quality\": number (1-5),\n",
        "  \"fake_notes\": \"detailed analysis of misdirection effectiveness\",\n",
        "  \"diversity_issues\": [\"list specific problems found\"],\n",
        "  \"difficulty\": number (1-5),\n",
        "  \"difficulty_reasoning\": \"detailed explanation\",\n",
        "  \"overall_notes\": \"comprehensive summary\"\n",
        "}}\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = analysis_model.invoke([HumanMessage(analysis_prompt)])\n",
        "        return extract_json_from_response(response.content)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ LLM analysis failed: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "rdYVHNS9lv5r"
      },
      "outputs": [],
      "source": [
        "# Load data from your manual analysis CSV\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file from your manual analysis\n",
        "df = pd.read_csv(\"10_rounds_clues_analysis.csv\")  # Change filename as needed\n",
        "\n",
        "# Group data by test_run and round to reconstruct round_data\n",
        "all_results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex9epMELiCFt",
        "outputId": "3acb14c5-49db-47e6-e947-a335d1e1b0ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing Test 1, Round 1: Movie - movie\n",
            "  ✅ Analyzed successfully\n",
            "Analyzing Test 1, Round 2: Movie - Star Wars Episode I: The Phantom Menace\n",
            "  ✅ Analyzed successfully\n",
            "Analyzing Test 2, Round 1: Song - song\n",
            "  ✅ Analyzed successfully\n",
            "Analyzing Test 2, Round 2: Song - Bohemian Rhapsody - Queen\n",
            "  ✅ Analyzed successfully\n",
            "Analyzing Test 3, Round 1: Book - Book\n",
            "  ✅ Analyzed successfully\n",
            "Analyzing Test 3, Round 2: Book - Harry Potter and the Sorcerer's Stone\n",
            "  ✅ Analyzed successfully\n",
            "Analyzing Test 4, Round 1: TV Show - TV Show\n",
            "  ✅ Analyzed successfully\n",
            "Analyzing Test 4, Round 2: TV Show - Breaking Bad\n",
            "  ✅ Analyzed successfully\n",
            "Analyzing Test 5, Round 1: Video Game - Video Game\n",
            "  ✅ Analyzed successfully\n",
            "Analyzing Test 5, Round 2: Video Game - The Legend of Zelda: Breath of the Wild\n",
            "  ✅ Analyzed successfully\n",
            "Analyzing Test 6, Round 1: Food - food\n",
            "  ✅ Analyzed successfully\n",
            "Analyzing Test 6, Round 2: Food - Pizza Margherita\n",
            "  ✅ Analyzed successfully\n",
            "Analyzing Test 7, Round 1: Animal - animal\n",
            "  ✅ Analyzed successfully\n",
            "Analyzing Test 7, Round 2: Animal - African Elephant\n",
            "  ✅ Analyzed successfully\n",
            "Analyzing Test 8, Round 1: Sport - Sport\n",
            "  ✅ Analyzed successfully\n",
            "Analyzing Test 8, Round 2: Sport - Tennis\n",
            "  ✅ Analyzed successfully\n",
            "Analyzing Test 9, Round 1: Country - Country\n",
            "  ✅ Analyzed successfully\n",
            "Analyzing Test 9, Round 2: Country - Japan\n",
            "  ✅ Analyzed successfully\n",
            "Analyzing Test 10, Round 1: Historical Event - Historical Event\n",
            "  ✅ Analyzed successfully\n",
            "Analyzing Test 10, Round 2: Historical Event - Moon Landing 1969\n",
            "  ✅ Analyzed successfully\n"
          ]
        }
      ],
      "source": [
        "for (test_run, round_num), group in df.groupby(['test_run', 'round']):\n",
        "    # Skip disinformer instructions\n",
        "    clue_data = group[group['clue_type'] != 'disinformer_instruction']\n",
        "\n",
        "    if len(clue_data) == 0:\n",
        "        continue\n",
        "\n",
        "    # Get basic info\n",
        "    topic_category = clue_data['topic_category'].iloc[0]\n",
        "    topic_specific = clue_data['topic_specific'].iloc[0]\n",
        "    answer = clue_data['answer'].iloc[0]\n",
        "    choices = clue_data['choices'].iloc[0]\n",
        "\n",
        "    print(f\"Analyzing Test {test_run}, Round {round_num}: {topic_category} - {answer}\")\n",
        "\n",
        "    # Reconstruct round_data from CSV\n",
        "    round_data = {\n",
        "        \"answer\": answer,\n",
        "        \"choices\": choices.split(\" | \") if choices else [],\n",
        "        \"informed_clues\": clue_data[clue_data['clue_type'] == 'informed']['clue_text'].tolist(),\n",
        "        \"misinformed_clues\": clue_data[clue_data['clue_type'] == 'misinformed']['clue_text'].tolist(),\n",
        "        \"fake_clues\": clue_data[clue_data['clue_type'] == 'fake']['clue_text'].tolist(),\n",
        "        \"extra_clues\": clue_data[clue_data['clue_type'] == 'extra']['clue_text'].tolist()\n",
        "    }\n",
        "\n",
        "    # Analyze with LLM\n",
        "    analysis = analyze_round_with_llm(round_data, analysis_model)\n",
        "\n",
        "    if analysis:\n",
        "        result = {\n",
        "            \"test_run\": test_run,\n",
        "            \"topic_category\": topic_category,\n",
        "            \"topic_specific\": topic_specific,\n",
        "            \"round\": round_num,\n",
        "            \"answer\": answer,\n",
        "            \"choices\": choices,\n",
        "\n",
        "            # LLM Analysis Results\n",
        "            \"informed_quality\": analysis.get(\"informed_quality\", \"\"),\n",
        "            \"informed_notes\": analysis.get(\"informed_notes\", \"\"),\n",
        "            \"misinformed_quality\": analysis.get(\"misinformed_quality\", \"\"),\n",
        "            \"misinformed_notes\": analysis.get(\"misinformed_notes\", \"\"),\n",
        "            \"fake_quality\": analysis.get(\"fake_quality\", \"\"),\n",
        "            \"fake_notes\": analysis.get(\"fake_notes\", \"\"),\n",
        "            \"diversity_issues\": \"; \".join(analysis.get(\"diversity_issues\", [])),\n",
        "            \"difficulty\": analysis.get(\"difficulty\", \"\"),\n",
        "            \"difficulty_reasoning\": analysis.get(\"difficulty_reasoning\", \"\"),\n",
        "            \"overall_notes\": analysis.get(\"overall_notes\", \"\"),\n",
        "\n",
        "            # Word count and length compliance data\n",
        "            \"total_clues\": len(round_data[\"informed_clues\"]) + len(round_data[\"misinformed_clues\"]) + len(round_data[\"fake_clues\"]) + len(round_data[\"extra_clues\"]),\n",
        "            \"length_compliant_clues\": sum(1 for clue_type in [\"informed_clues\", \"misinformed_clues\", \"fake_clues\", \"extra_clues\"]\n",
        "                                        for clue in round_data[clue_type]\n",
        "                                        if 15 <= len(clue.split()) <= 20),\n",
        "            \"length_compliance_rate\": f\"{(sum(1 for clue_type in ['informed_clues', 'misinformed_clues', 'fake_clues', 'extra_clues'] for clue in round_data[clue_type] if 15 <= len(clue.split()) <= 20) / max(1, sum(len(round_data[clue_type]) for clue_type in ['informed_clues', 'misinformed_clues', 'fake_clues', 'extra_clues'])) * 100):.0f}%\",\n",
        "            \"avg_word_count\": round(sum(len(clue.split()) for clue_type in [\"informed_clues\", \"misinformed_clues\", \"fake_clues\", \"extra_clues\"] for clue in round_data[clue_type]) / max(1, sum(len(round_data[clue_type]) for clue_type in [\"informed_clues\", \"misinformed_clues\", \"fake_clues\", \"extra_clues\"])), 1)\n",
        "        }\n",
        "\n",
        "        all_results.append(result)\n",
        "        print(f\"  ✅ Analyzed successfully\")\n",
        "    else:\n",
        "        print(f\"  ❌ Analysis failed\")\n",
        "\n",
        "    sleep(2)  # Rate limiting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xayzwc_0iO-L",
        "outputId": "f1735cba-482e-4fec-c580-03c4e264fb10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ LLM analysis complete! Saved 27 results to: llm_analysis_results.csv\n"
          ]
        }
      ],
      "source": [
        "# Save results\n",
        "if all_results:\n",
        "    with open(\"llm_analysis_results.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=all_results[0].keys())\n",
        "        writer.writeheader()\n",
        "        writer.writerows(all_results)\n",
        "\n",
        "    print(f\"✅ LLM analysis complete! Saved {len(all_results)} results to: llm_analysis_results.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huUEGw7vUIFC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
