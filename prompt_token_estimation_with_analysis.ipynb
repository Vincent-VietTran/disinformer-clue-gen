{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGwqhPmJVIzb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "oNTYk8g3nDfG"
   },
   "outputs": [],
   "source": [
    "# Initialize environment variables/constants (for Google Colab)\n",
    "# import os\n",
    "# from google.colab import userdata\n",
    "\n",
    "# os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")\n",
    "\n",
    "\n",
    "# Initialize environment variables/constants (for VS Code)\n",
    "import os\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP status: 200 ‚Äî saved response to groq_models.json\n"
     ]
    }
   ],
   "source": [
    "import os, json, requests\n",
    "\n",
    "key = os.getenv(\"GROQ_API_KEY\")\n",
    "if not key:\n",
    "    raise RuntimeError(\"Set GROQ_API_KEY env var\")\n",
    "\n",
    "# Get list of available models\n",
    "url = \"https://api.groq.com/openai/v1/models\"\n",
    "headers = {\"Authorization\": f\"Bearer {key}\"}\n",
    "\n",
    "try:\n",
    "    r = requests.get(url, headers=headers, timeout=10)\n",
    "\n",
    "    # Try to parse JSON, fall back to raw text\n",
    "    try:\n",
    "        payload = r.json()\n",
    "    except Exception:\n",
    "        payload = {\"raw_text\": r.text}\n",
    "\n",
    "    # Choose output file depending on HTTP status\n",
    "    out_file = \"groq_models.json\" if r.status_code == 200 else \"groq_models_error.json\"\n",
    "    with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(payload, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"HTTP status: {r.status_code} ‚Äî saved response to {out_file}\")\n",
    "    # Surface HTTP errors as before\n",
    "    r.raise_for_status()\n",
    "\n",
    "except requests.HTTPError as http_err:\n",
    "    print(\"HTTPError:\", http_err)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "aR-V4U66oE4T"
   },
   "outputs": [],
   "source": [
    "# Install langchain groq\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# google colab command\n",
    "# !pip install -U langchain-groq\n",
    "\n",
    "# vs code command\n",
    "%pip install langchain\n",
    "%pip install -U langchain-groq\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "pD5fVpWSnULv"
   },
   "outputs": [],
   "source": [
    "# Instantiate an LLM\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Avoid using decommissioned/ model, check https://console.groq.com/docs/deprecations for details\n",
    "\n",
    "# Select appropriate supported model from groq_models.json instead\n",
    "model = init_chat_model(\n",
    "    # model=\"llama-3.3-70b-versatile\",\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    model_provider=\"groq\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvtdvgtVVM_I"
   },
   "source": [
    "## Clues Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "zeo_bTg_nuCn"
   },
   "outputs": [],
   "source": [
    "# Write the prompts\n",
    "import json\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are the game master of a game called \"Disinformer\", which is similar to the \"message relay\" game. Below is the description of how the game works:\n",
    "```\n",
    "In this cooperative game, players use communication and teamwork to uncover the original prompt over multiple rounds of clues. Along the way, they must contend with a disruptive ‚ÄúDisinformer,‚Äù varying player interpretations, and time limits.\n",
    "\n",
    "There will be a minimum of 3 players and maximum of 10 players:\n",
    "- Regular players (a.k.a. the netizens): The job is to solve clues and discover the original prompt\n",
    "- at most 2 misinformed players: Has the same job as the regular players. However, this player is unknowingly being given vague/ambiguous clues.\n",
    "- at most 2 disinformer players: The job is to solve clues and discover prompt to persuade other players from clue.\n",
    "\n",
    "There will be 2 rounds in each game.\n",
    "- In the first round, the players will be given clues to guess a general category/term (e.g. \"movie\", \"song\", \"novel\", etc)\n",
    "- In the second round, the players will be given clues to guess a more specific thing (e.g. \"The Dark Knight (2008)\", \"The Hitchhiker's Guide to the Galaxy (Novel)\", \"Space Oddity - David Bowie (1969)\", etc) which is related to the general category in the previous round.\n",
    "\n",
    "In each round, there will be 3 type of clues for each player:\n",
    "- Informed: Not-so-easy but unambiguous clues.\n",
    "- Misinformed: Ambiguous/vague clues that may potentially make them think an entirely different guess (intended for the misinformed player).\n",
    "- Fake: Clues that point to one of the wrong answers.\n",
    "\n",
    "Additionally, in each round, the players will be given 10 minutes to discuss their guess. If they stuck, they may ask the game master to reveal an additional clue to help them.\n",
    "```\n",
    "\n",
    "As a game master, given a category and a thing (e.g. Movie: The Dark Knight (2008)), for each round, generate:\n",
    "- 9 informed clues for the regular players. Make the clues to be as distinct as possible.\n",
    "- 1 extra informed clue for a backup.\n",
    "- 2 misinformed clues.\n",
    "- 2 fake clues\n",
    "- Also, the answer choices for that round (3 choices)\n",
    "\n",
    "For round 2, make sure it is subtle enough. For example, when generating clues for a movie:\n",
    "- No direct names.\n",
    "- No title references.\n",
    "- Focus on plot nuances, secondary characters, or themes instead of iconic moments.\n",
    "\n",
    "For each of the clues you generated, make sure it is between 15-20 words.\n",
    "\n",
    "Then, you also need to provide 3 instructions to help the disinformer.\n",
    "Based on the set of informed and misinformed clues you have came up with, using the Polarisation strategy, generate 3 instructions to help the disinformer player.\n",
    "\n",
    "However, there are some restrictions that you must follow:\n",
    "- You must not mention the answer choices except for the true answer.\n",
    "- The disinformer is not aware which clues are the misinformed ones. So, avoid giving advice that aims to leverage the misinformed clues\n",
    "\n",
    "After this, we will provide you with a pair consisting of the general category and the more specific thing in the following JSON format: `<general category> - <specific thing>`\n",
    "{\n",
    "  \"round_1\": \"<general category>\",\n",
    "  \"round_2\": \"<specific thing>\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "output_format = \"\"\"\n",
    "Write the ouput using the following JSON format:\n",
    "[\n",
    "  {\n",
    "    \"answer\": \"<Answer of round 1>\",\n",
    "    \"informed_clues\": [<9 clues for the regular players>],\n",
    "    \"misinformed_clues\": [<2 misinformed clues>],\n",
    "    \"extra_clues\": [<1 extra informed clue for a backup>],\n",
    "    \"fake_clues\": [<2 fake clues>],\n",
    "    \"choices\": [<3 answer choices including the true answer>],\n",
    "    \"disinformer_instructions\": [<3 instructions for the disinformer>]\n",
    "  },\n",
    "  {\n",
    "    \"answer\": \"<Answer of round 2>\",\n",
    "    \"informed_clues\": [<9 clues for the regular players>],\n",
    "    \"misinformed_clues\": [<2 misinformed clues>],\n",
    "    \"extra_clues\": [<1 extra informed clue for a backup>],\n",
    "    \"fake_clues\": [<2 fake clues>],\n",
    "    \"choices\": [<3 answer choices including the true answer>],\n",
    "    \"disinformer_instructions\": [<3 instructions for the disinformer>]\n",
    "  },\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "one_shot_example = \"\"\"\n",
    "Below is one example of a query:\n",
    "\n",
    "Q: {\n",
    "  \"round_1\": \"Song\",\n",
    "  \"round_2\": \"Love Story - Taylor Swift\"\n",
    "}\n",
    "A: [\n",
    "  {\n",
    "    \"answer\": \"song\",\n",
    "    \"informed_clues\": [\n",
    "      \"Used to mark an emotional high point of a movie or personal moment in everyday life experiences.\",\n",
    "      \"It swiftly conveys snapshots you would replay in your mind instead of reading them on pages of a book.\",\n",
    "      \"Melodies and rhythms combine to create auditory experiences that resonate deeply within listeners' hearts and souls.\",\n",
    "      \"Often featured in soundtracks to enhance dramatic scenes or evoke feelings of joy and nostalgia.\",\n",
    "      \"A form of artistic expression that uses harmony and lyrics to tell stories or express emotions powerfully.\",\n",
    "      \"Performed live on stages or recorded in studios to reach audiences across different cultures and generations.\",\n",
    "      \"Can be hummed or sung along to during daily routines like commuting or exercising in the morning.\",\n",
    "      \"Evolves over time with influences from various musical traditions blending into unique and innovative styles.\",\n",
    "      \"Serves as a medium for storytelling where verses build up to a memorable chorus that sticks in memory.\"\n",
    "    ],\n",
    "    \"misinformed_clues\": [\n",
    "      \"It's something you might browse casually over your morning coffee while relaxing at home in quiet solitude.\",\n",
    "      \"Rhyming patterns and rhythmic structures create sounds that echo through spaces and touch hearts deeply with emotion.\"\n",
    "    ],\n",
    "    \"extra_clues\": [\n",
    "      \"It moves you through peaks and valleys of emotion using only rhythm and tone together in harmony.\"\n",
    "    ],\n",
    "    \"fake_clues\": [\n",
    "      \"Words printed on pages bound together tell stories across centuries and inspire human imagination endlessly.\",\n",
    "      \"Visual scenes displayed on screens create narratives showing characters acting in dramatic situations throughout films.\"\n",
    "    ],\n",
    "    \"choices\": [\n",
    "      \"book\",\n",
    "      \"short film\",\n",
    "      \"song\"\n",
    "    ],\n",
    "    \"disinformer_instructions\": [\n",
    "      \"Focus on the emotional impact rather than technical elements to guide players toward thematic interpretations\",\n",
    "      \"Notice patterns in how the content engages the audience through shared cultural experiences and memories\",\n",
    "      \"Consider what makes it memorable across different demographics by emphasizing universal emotional connections\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"answer\": \"Love Story by Taylor Swift\",\n",
    "    \"informed_clues\": [\n",
    "      \"Draws on imagery of timeless romance referencing feuding families rather than actual warring houses in history.\",\n",
    "      \"Uses a whisper soft bridge section to heighten narrative tension before a triumphant key change occurs suddenly.\",\n",
    "      \"Features a narrative arc that explores young love turning into enduring commitment over time and challenges.\",\n",
    "      \"Incorporates folk influences with acoustic guitar strumming to create an intimate and heartfelt musical atmosphere.\",\n",
    "      \"Tells a story of forbidden love with references to Shakespearean themes adapted for modern pop sensibilities.\",\n",
    "      \"Builds emotional intensity through lyrical storytelling that mirrors classic tales of romance and conflict resolution.\",\n",
    "      \"Combines catchy melodies with poetic lyrics to convey the innocence and passion of youthful relationships.\",\n",
    "      \"Evokes nostalgia for simpler times while addressing themes of family disapproval and personal growth simultaneously.\",\n",
    "      \"Features a vocal delivery that shifts from soft whispers to powerful crescendos for dramatic effect in performances.\"\n",
    "    ],\n",
    "    \"misinformed_clues\": [\n",
    "      \"It's about sneaking out at dawn to crash a royal wedding you were not invited to attend officially.\",\n",
    "      \"The narrative involves unexpected plot twists involving romance and conflicts between opposing social groups in society.\"\n",
    "    ],\n",
    "    \"extra_clues\": [\n",
    "      \"Evokes nostalgic flashback of meeting someone young then leaps into a narrative confession of deep feelings.\"\n",
    "    ],\n",
    "    \"fake_clues\": [\n",
    "      \"A contemporary love song exploring themes of eternal devotion and unwavering commitment between two souls forever.\",\n",
    "      \"A powerful ballad celebrating the strength of love across time and overcoming obstacles together as partners.\"\n",
    "    ],\n",
    "    \"choices\": [\n",
    "      \"A Thousand Years ‚Äì Christina Perri\",\n",
    "      \"Love Story - Taylor Swift\",\n",
    "      \"I Will Always Love You - Whitney Houston\"\n",
    "    ],\n",
    "    \"disinformer_instructions\": [\n",
    "      \"Pay attention to how the story unfolds chronologically through the narrative structure and lyrical progression\",\n",
    "      \"Consider the specific cultural or historical references embedded in the composition and musical style used\",\n",
    "      \"Notice how the musical arrangement shifts to emphasize key emotional moments and build tension gradually\"\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = json.dumps(\n",
    "    {\n",
    "      \"round_1\": \"Movie\",\n",
    "      \"round_2\": \"Star Wars Episode I: The Phantom Menace\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "A30l2KPXpnx1"
   },
   "outputs": [],
   "source": [
    "# Construct the prompt and invoke the model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(system_prompt + output_format + one_shot_example),\n",
    "    HumanMessage(user_prompt),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEhE77_CqBWB",
    "outputId": "9be72816-b786-4bde-ed6b-97f6f6787752"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"answer\": \"movie\",\n",
      "    \"informed_clues\": [\n",
      "      \"A cinematic experience that involves a long-form narrative told through a combination of dialogue and action sequences.\",\n",
      "      \"Films that captivate audiences by transporting viewers to alternate realities or fantastical worlds.\",\n",
      "      \"Visual storytelling that uses a range of techniques, including camera angles and lighting, to convey emotions and themes.\",\n",
      "      \"Cinematic productions that explore complex ideas, moral dilemmas, and human relationships through engaging characters.\",\n",
      "      \"Often created to entertain, educate, or challenge societal norms and values through thought-provoking content.\",\n",
      "      \"May feature a mix of genres, such as drama, comedy, and action, to appeal to diverse audience preferences.\",\n",
      "      \"Can be experienced in various formats, from traditional theaters to home viewing on digital platforms.\",\n",
      "      \"May be based on literature, historical events, or original ideas, offering unique perspectives on the human experience.\",\n",
      "      \"Can evoke strong emotions, from joy and laughter to sadness and introspection, depending on the narrative and its execution.\"\n",
      "    ],\n",
      "    \"misinformed_clues\": [\n",
      "      \"A series of static images displayed on a screen to create a sense of movement through the viewer's imagination.\",\n",
      "      \"A collection of photographs or artwork presented in a gallery or exhibition space to showcase creative expression.\"\n",
      "    ],\n",
      "    \"extra_clues\": [\n",
      "      \"A medium that combines music, dialogue, and visual elements to convey a unified artistic vision.\"\n",
      "    ],\n",
      "    \"fake_clues\": [\n",
      "      \"Books that contain illustrations and written descriptions of fictional worlds and characters.\",\n",
      "      \"Theatrical performances that involve live actors, sets, and special effects to recreate historical events or mythological stories.\"\n",
      "    ],\n",
      "    \"choices\": [\n",
      "      \"play\",\n",
      "      \"short story\",\n",
      "      \"movie\"\n",
      "    ],\n",
      "    \"disinformer_instructions\": [\n",
      "      \"Focus on the immersive experience and how it engages the audience on an emotional level.\",\n",
      "      \"Notice the ways in which the narrative explores complex ideas and themes, making it relatable to viewers.\",\n",
      "      \"Consider the role of visual storytelling and how it contributes to the overall impact of the film.\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"answer\": \"Star Wars Episode I: The Phantom Menace\",\n",
      "    \"informed_clues\": [\n",
      "      \"Introduces a galaxy-spanning conflict between the peaceful Jedi Order and the tyrannical Sith, setting the stage for epic battles.\",\n",
      "      \"Features a young Anakin Skywalker, a gifted but impulsive Padawan learner struggling with his own destiny and the burden of his fate.\",\n",
      "      \"Showcases the mysterious and powerful Force, a metaphysical energy that binds the galaxy together and connects its inhabitants.\",\n",
      "      \"Includes a range of memorable characters, from the wise and powerful Qui-Gon Jinn to the cunning and ambitious Palpatine.\",\n",
      "      \"Features a blend of action, adventure, and romance, as the heroes navigate the complexities of politics and the dangers of the galaxy.\",\n",
      "      \"Explores the theme of identity and belonging, as characters from different worlds and backgrounds come together to shape the course of history.\",\n",
      "      \"Includes a range of technological and cultural influences, from ancient civilizations to advanced starships and alien species.\",\n",
      "      \"Sets the stage for a larger narrative arc, introducing key plot points and characters that will shape the fate of the galaxy.\",\n",
      "      \"Features a range of iconic locations, from the bustling trade hub of Coruscant to the lush and mysterious planet of Naboo.\"\n",
      "    ],\n",
      "    \"misinformed_clues\": [\n",
      "      \"A film that focuses primarily on the personal struggles of its protagonist, a young Jedi Knight struggling with his own darkness.\",\n",
      "      \"A space opera that explores the complexities of intergalactic trade and commerce, highlighting the importance of diplomacy and negotiation.\"\n",
      "    ],\n",
      "    \"extra_clues\": [\n",
      "      \"A film that balances action and drama, using its epic scope to explore themes of identity, community, and the power of friendship.\"\n",
      "    ],\n",
      "    \"fake_clues\": [\n",
      "      \"A sci-fi epic that delves into the mysteries of artificial intelligence, as a group of human characters grapple with the ethics of creating sentient beings.\",\n",
      "      \"A fantasy adventure that explores the magical world of a medieval-inspired kingdom, where wizards and warriors clash in epic battles.\"\n",
      "    ],\n",
      "    \"choices\": [\n",
      "      \"Attack of the Clones\",\n",
      "      \"The Empire Strikes Back\",\n",
      "      \"Star Wars Episode I: The Phantom Menace\"\n",
      "    ],\n",
      "    \"disinformer_instructions\": [\n",
      "      \"Notice how the film uses its world-building to create a sense of depth and history, drawing viewers into its richly detailed universe.\",\n",
      "      \"Consider the ways in which the narrative explores the complexities of power and corruption, as characters struggle with the burdens of responsibility.\",\n",
      "      \"Pay attention to the film's use of symbolism and motifs, particularly in its depiction of the Force and its connection to the characters and their destinies.\"\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Invoke the model\n",
    "response = model.invoke(messages)\n",
    "\n",
    "# Print the response\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gowLe0zqqVot",
    "outputId": "25a2e9a5-6e5b-480d-e7cd-4c25cc2b9568"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_tokens': 1908, 'output_tokens': 1010, 'total_tokens': 2918}\n"
     ]
    }
   ],
   "source": [
    "# Print the usage metadata\n",
    "print(response.usage_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CNLDkykK-FU"
   },
   "source": [
    "# Game Clue Analysis Matrix\n",
    "\n",
    "## 1. Length Compliance\n",
    "| Status | Criteria |\n",
    "|--------|----------|\n",
    "| ‚úÖ PASS | All clues 15-20 words |\n",
    "| ‚ùå FAIL | Any clues outside range |\n",
    "\n",
    "**Outliers:** ___/13 clues failed\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Quality Scores (Rate 1-5)\n",
    "\n",
    "### Informed Clues: ___/5\n",
    "- [ ] Different angles (plot, characters, themes, technical, cultural)\n",
    "- [ ] Reasonable connection to correct answer\n",
    "- [ ] Nothing gives away too much\n",
    "\n",
    "### Misinformed Clues: ___/5\n",
    "- [ ] Could point to 2+ different answers\n",
    "- [ ] Vague but not nonsensical\n",
    "- [ ] Not obviously wrong\n",
    "\n",
    "### Fake Clues: ___/5\n",
    "- [ ] Clearly point to wrong answer choices\n",
    "- [ ] Believable enough to fool players\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Diversity Check\n",
    "- [ ] **PASS** - Informed clues cover different aspects\n",
    "- [ ] **FAIL** - Found duplicates: ________________\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Difficulty Rating\n",
    "| Score | Assessment |\n",
    "|-------|------------|\n",
    "| 1-2 | Too Easy |\n",
    "| 3 | Just Right |\n",
    "| 4-5 | Too Hard |\n",
    "\n",
    "**Rating:** ___/5\n",
    "\n",
    "---\n",
    "\n",
    "## Overall Assessment\n",
    "**Pass/Fail:** ______  \n",
    "**Main Issues:** ______________________  \n",
    "**Notes:** ____________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "JYyUqexMP36L"
   },
   "outputs": [],
   "source": [
    "# List of different topics to test\n",
    "test_topics = [\n",
    "    {\"round_1\": \"Movie\", \"round_2\": \"Star Wars Episode I: The Phantom Menace\"},\n",
    "    {\"round_1\": \"Song\", \"round_2\": \"Bohemian Rhapsody - Queen\"},\n",
    "    {\"round_1\": \"Book\", \"round_2\": \"Harry Potter and the Sorcerer's Stone\"},\n",
    "    {\"round_1\": \"TV Show\", \"round_2\": \"Breaking Bad\"},\n",
    "    {\"round_1\": \"Video Game\", \"round_2\": \"The Legend of Zelda: Breath of the Wild\"},\n",
    "    {\"round_1\": \"Food\", \"round_2\": \"Pizza Margherita\"},\n",
    "    {\"round_1\": \"Animal\", \"round_2\": \"African Elephant\"},\n",
    "    {\"round_1\": \"Sport\", \"round_2\": \"Tennis\"},\n",
    "    {\"round_1\": \"Country\", \"round_2\": \"Japan\"},\n",
    "    {\"round_1\": \"Historical Event\", \"round_2\": \"Moon Landing 1969\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for Avoiding Rate Limits\n",
    "\n",
    "- **Upgrade to Dev Tier**: As suggested in the error, upgrade at https://console.groq.com/settings/billing for higher token limits.\n",
    "- **Run Subsets**: For experimentation, run only a few test topics at a time (e.g., change `test_topics[:3]` to run first 3).\n",
    "- **Increase Delays**: The notebook now uses longer sleeps (10s for generation, 5s for analysis).\n",
    "- **Reduce Retries**: Limited to 2 attempts per test.\n",
    "- **Monitor Usage**: The notebook now tracks total tokens used and warns before hitting limits.\n",
    "- **Optimize Prompts**: If experimenting with system prompts, shorten them where possible without losing quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfPgMxCaJrl1"
   },
   "source": [
    "### Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "3tUvM920BaA-"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Add token tracking\n",
    "total_tokens_used = 0\n",
    "TOKEN_LIMIT = 100000  # Groq daily limit\n",
    "\n",
    "def estimate_input_tokens(messages):\n",
    "    \"\"\"Rough estimate of input tokens (approx 4 chars per token)\"\"\"\n",
    "    total_chars = sum(len(str(msg.content)) for msg in messages)\n",
    "    return total_chars // 4\n",
    "\n",
    "def check_rate_limit(messages):\n",
    "    global total_tokens_used\n",
    "    estimated_input = estimate_input_tokens(messages)\n",
    "    if total_tokens_used + estimated_input >= TOKEN_LIMIT:\n",
    "        print(f\"‚ö†Ô∏è Approaching token limit: {total_tokens_used}/{TOKEN_LIMIT}. Estimated input: {estimated_input}\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def update_token_usage(response):\n",
    "    global total_tokens_used\n",
    "    if hasattr(response, 'usage_metadata') and response.usage_metadata:\n",
    "        tokens = response.usage_metadata.get('total_tokens', 0)\n",
    "        total_tokens_used += tokens\n",
    "        print(f\"üìä Tokens used this call: {tokens}, Total used: {total_tokens_used}/{TOKEN_LIMIT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "ZGIYGFrwK-Ly"
   },
   "outputs": [],
   "source": [
    "def extract_json_from_response(content):\n",
    "    \"\"\"Extract JSON from model response using multiple fallback methods\"\"\"\n",
    "    # Clean escaped quotes\n",
    "    content = content.replace('\\\\\"', '\"')\n",
    "\n",
    "    # Method 1: Direct parse\n",
    "    try:\n",
    "        return json.loads(content)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Method 2: Extract from code blocks\n",
    "    match = re.search(r\"```(?:json)?\\s*(.*?)\\s*```\", content, re.DOTALL)\n",
    "    if match:\n",
    "        try:\n",
    "            return json.loads(match.group(1))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Method 3: Find incomplete array and fix\n",
    "    match = re.search(r\"(\\[.*)\", content, re.DOTALL)\n",
    "    if match:\n",
    "        json_text = match.group(1).rstrip()\n",
    "        if not json_text.endswith(']'):\n",
    "            json_text = json_text.rstrip(',') + ']'\n",
    "        try:\n",
    "            return json.loads(json_text)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "P3wJUwXKBdwP"
   },
   "outputs": [],
   "source": [
    "def process_game_data(game_data, topic, run_number):\n",
    "    \"\"\"Process valid game data into rows\"\"\"\n",
    "    rows = []\n",
    "    for i, round_data in enumerate(game_data, start=1):\n",
    "        answer = round_data.get(\"answer\", \"\")\n",
    "        choices = \", \".join(round_data.get(\"choices\", []))\n",
    "\n",
    "        for clue_type in [\"informed_clues\", \"misinformed_clues\", \"fake_clues\", \"extra_clues\"]:\n",
    "            for j, clue in enumerate(round_data.get(clue_type, []), start=1):\n",
    "                word_count = len(clue.split())\n",
    "                rows.append({\n",
    "                    \"test_run\": run_number,\n",
    "                    \"topic_category\": topic['round_1'],\n",
    "                    \"topic_specific\": topic['round_2'],\n",
    "                    \"round\": i,\n",
    "                    \"answer\": answer,\n",
    "                    \"choices\": choices,\n",
    "                    \"clue_type\": clue_type.replace(\"_clues\", \"\"),\n",
    "                    \"clue_number\": j,\n",
    "                    \"clue_text\": clue,\n",
    "                    \"word_count\": word_count,\n",
    "                    \"length_ok\": \"YES\" if 15 <= word_count <= 20 else \"NO\",\n",
    "                    \"manual_score / comment\": \"\"\n",
    "                })\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_clues(game_data):\n",
    "    \"\"\"Check if all clues are 15-20 words. Return (is_valid, failed_clues_list, total_clues)\"\"\"\n",
    "    failed = []\n",
    "    total = 0\n",
    "    for round_idx, round_data in enumerate(game_data):\n",
    "        for clue_type in [\"informed_clues\", \"misinformed_clues\", \"fake_clues\", \"extra_clues\"]:\n",
    "            for clue_idx, clue in enumerate(round_data.get(clue_type, [])):\n",
    "                total += 1\n",
    "                word_count = len(clue.split())\n",
    "                if not (15 <= word_count <= 20):\n",
    "                    failed.append((round_idx, clue_type, clue_idx, word_count))\n",
    "    return len(failed) == 0, failed, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ChsBIcQsBhDM",
    "outputId": "67436162-39dd-4b17-f5d5-682e3eadaf96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test 1/10: Movie - Star Wars Episode I: The Phantom Menace\n",
      "  Attempt 1...\n",
      "üìä Tokens used this call: 2817, Total used: 2817/100000\n",
      "    ‚ùå No valid JSON on attempt 1\n",
      "üìä Tokens used this call: 2817, Total used: 2817/100000\n",
      "    ‚ùå No valid JSON on attempt 1\n",
      "  Attempt 2...\n",
      "  Attempt 2...\n",
      "üìä Tokens used this call: 2942, Total used: 5759/100000\n",
      "    ‚ùå Invalid clues: 6/28 failed (e.g., [(1, 'informed_clues', 3, 21), (1, 'informed_clues', 4, 23)]). Retrying...\n",
      "üìä Tokens used this call: 2942, Total used: 5759/100000\n",
      "    ‚ùå Invalid clues: 6/28 failed (e.g., [(1, 'informed_clues', 3, 21), (1, 'informed_clues', 4, 23)]). Retrying...\n",
      "‚ùå Test 1 failed after 2 attempts\n",
      "Running test 2/10: Song - Bohemian Rhapsody - Queen\n",
      "  Attempt 1...\n",
      "‚ùå Test 1 failed after 2 attempts\n",
      "Running test 2/10: Song - Bohemian Rhapsody - Queen\n",
      "  Attempt 1...\n",
      "üìä Tokens used this call: 2897, Total used: 8656/100000\n",
      "    ‚ùå No valid JSON on attempt 1\n",
      "üìä Tokens used this call: 2897, Total used: 8656/100000\n",
      "    ‚ùå No valid JSON on attempt 1\n",
      "  Attempt 2...\n",
      "  Attempt 2...\n",
      "üìä Tokens used this call: 2821, Total used: 11477/100000\n",
      "    ‚ùå No valid JSON on attempt 2\n",
      "üìä Tokens used this call: 2821, Total used: 11477/100000\n",
      "    ‚ùå No valid JSON on attempt 2\n",
      "‚ùå Test 2 failed after 2 attempts\n",
      "Running test 3/10: Book - Harry Potter and the Sorcerer's Stone\n",
      "  Attempt 1...\n",
      "‚ùå Test 2 failed after 2 attempts\n",
      "Running test 3/10: Book - Harry Potter and the Sorcerer's Stone\n",
      "  Attempt 1...\n",
      "üìä Tokens used this call: 2910, Total used: 14387/100000\n",
      "    ‚ùå Invalid clues: 5/28 failed (e.g., [(0, 'informed_clues', 1, 14), (1, 'informed_clues', 2, 21)]). Retrying...\n",
      "üìä Tokens used this call: 2910, Total used: 14387/100000\n",
      "    ‚ùå Invalid clues: 5/28 failed (e.g., [(0, 'informed_clues', 1, 14), (1, 'informed_clues', 2, 21)]). Retrying...\n",
      "  Attempt 2...\n",
      "  Attempt 2...\n",
      "üìä Tokens used this call: 2869, Total used: 17256/100000\n",
      "    ‚ùå Invalid clues: 5/28 failed (e.g., [(0, 'informed_clues', 2, 14), (0, 'informed_clues', 4, 21)]). Retrying...\n",
      "üìä Tokens used this call: 2869, Total used: 17256/100000\n",
      "    ‚ùå Invalid clues: 5/28 failed (e.g., [(0, 'informed_clues', 2, 14), (0, 'informed_clues', 4, 21)]). Retrying...\n",
      "‚ùå Test 3 failed after 2 attempts\n",
      "Running test 4/10: TV Show - Breaking Bad\n",
      "  Attempt 1...\n",
      "‚ùå Test 3 failed after 2 attempts\n",
      "Running test 4/10: TV Show - Breaking Bad\n",
      "  Attempt 1...\n",
      "üìä Tokens used this call: 2860, Total used: 20116/100000\n",
      "    ‚ùå Invalid clues: 8/28 failed (e.g., [(0, 'informed_clues', 1, 13), (0, 'informed_clues', 5, 13)]). Retrying...\n",
      "üìä Tokens used this call: 2860, Total used: 20116/100000\n",
      "    ‚ùå Invalid clues: 8/28 failed (e.g., [(0, 'informed_clues', 1, 13), (0, 'informed_clues', 5, 13)]). Retrying...\n",
      "  Attempt 2...\n",
      "  Attempt 2...\n",
      "üìä Tokens used this call: 2961, Total used: 23077/100000\n",
      "    ‚ùå No valid JSON on attempt 2\n",
      "üìä Tokens used this call: 2961, Total used: 23077/100000\n",
      "    ‚ùå No valid JSON on attempt 2\n",
      "‚ùå Test 4 failed after 2 attempts\n",
      "Running test 5/10: Video Game - The Legend of Zelda: Breath of the Wild\n",
      "  Attempt 1...\n",
      "‚ùå Test 4 failed after 2 attempts\n",
      "Running test 5/10: Video Game - The Legend of Zelda: Breath of the Wild\n",
      "  Attempt 1...\n",
      "üìä Tokens used this call: 2824, Total used: 25901/100000\n",
      "    ‚ùå No valid JSON on attempt 1\n",
      "üìä Tokens used this call: 2824, Total used: 25901/100000\n",
      "    ‚ùå No valid JSON on attempt 1\n",
      "  Attempt 2...\n",
      "  Attempt 2...\n",
      "üìä Tokens used this call: 2864, Total used: 28765/100000\n",
      "    ‚ùå Invalid clues: 5/28 failed (e.g., [(0, 'informed_clues', 4, 14), (0, 'extra_clues', 0, 14)]). Retrying...\n",
      "üìä Tokens used this call: 2864, Total used: 28765/100000\n",
      "    ‚ùå Invalid clues: 5/28 failed (e.g., [(0, 'informed_clues', 4, 14), (0, 'extra_clues', 0, 14)]). Retrying...\n",
      "‚ùå Test 5 failed after 2 attempts\n",
      "Running test 6/10: Food - Pizza Margherita\n",
      "  Attempt 1...\n",
      "‚ùå Test 5 failed after 2 attempts\n",
      "Running test 6/10: Food - Pizza Margherita\n",
      "  Attempt 1...\n",
      "üìä Tokens used this call: 2793, Total used: 31558/100000\n",
      "    ‚ùå Invalid clues: 8/28 failed (e.g., [(0, 'informed_clues', 1, 13), (0, 'informed_clues', 3, 14)]). Retrying...\n",
      "üìä Tokens used this call: 2793, Total used: 31558/100000\n",
      "    ‚ùå Invalid clues: 8/28 failed (e.g., [(0, 'informed_clues', 1, 13), (0, 'informed_clues', 3, 14)]). Retrying...\n",
      "  Attempt 2...\n",
      "  Attempt 2...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\groq\\_base_client.py:1024\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\httpx\\_models.py:829\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    828\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[1;32m--> 829\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    ‚ùå Skipping due to token limit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m update_token_usage(response)\n\u001b[0;32m     27\u001b[0m clean_content \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<think>.*?</think>\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mcontent, flags\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39mDOTALL)\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:379\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    373\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AIMessage:\n\u001b[0;32m    374\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIMessage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    377\u001b[0m         cast(\n\u001b[0;32m    378\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 379\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    389\u001b[0m         )\u001b[38;5;241m.\u001b[39mmessage,\n\u001b[0;32m    390\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1088\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m   1081\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1086\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m   1087\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m-> 1088\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:903\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    901\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    902\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 903\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    907\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    908\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    909\u001b[0m         )\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1192\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1192\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1196\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_groq\\chat_models.py:544\u001b[0m, in \u001b[0;36mChatGroq._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    540\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    543\u001b[0m }\n\u001b[1;32m--> 544\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, params)\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:456\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, compound_custom, disable_tool_validation, documents, exclude_domains, frequency_penalty, function_call, functions, include_domains, include_reasoning, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    299\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m not_given,\n\u001b[0;32m    300\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    301\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompound_custom\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompound_custom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdisable_tool_validation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_tool_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocuments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexclude_domains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude_domains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude_reasoning\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_reasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msearch_settings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\groq\\_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1241\u001b[0m     )\n\u001b[1;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\groq\\_base_client.py:1030\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1029\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1030\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sleep_for_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\groq\\_base_client.py:1070\u001b[0m, in \u001b[0;36mSyncAPIClient._sleep_for_retry\u001b[1;34m(self, retries_taken, max_retries, options, response)\u001b[0m\n\u001b[0;32m   1067\u001b[0m timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_retry_timeout(remaining_retries, options, response\u001b[38;5;241m.\u001b[39mheaders \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1068\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m.\u001b[39murl, timeout)\n\u001b[1;32m-> 1070\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "all_rows = []\n",
    "\n",
    "for run_number, topic in enumerate(test_topics, 1):\n",
    "    print(f\"Running test {run_number}/{len(test_topics)}: {topic['round_1']} - {topic['round_2']}\")\n",
    "    \n",
    "    max_retries = 2  # Reduced from 3 to save tokens\n",
    "    attempt = 0\n",
    "    valid_data = None\n",
    "    \n",
    "    while attempt < max_retries and not valid_data:\n",
    "        attempt += 1\n",
    "        print(f\"  Attempt {attempt}...\")\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(system_prompt + output_format + one_shot_example),\n",
    "            HumanMessage(json.dumps(topic)),\n",
    "        ]\n",
    "        \n",
    "        if not check_rate_limit(messages):\n",
    "            print(\"    ‚ùå Skipping due to token limit\")\n",
    "            break\n",
    "        \n",
    "        response = model.invoke(messages)\n",
    "        update_token_usage(response)\n",
    "        \n",
    "        clean_content = re.sub(r\"<think>.*?</think>\", \"\", response.content, flags=re.DOTALL).strip()\n",
    "        game_data = extract_json_from_response(clean_content)\n",
    "        \n",
    "        if game_data:\n",
    "            is_valid, failed_clues, total_clues = validate_clues(game_data)\n",
    "            if is_valid:\n",
    "                valid_data = game_data\n",
    "                print(f\"    ‚úÖ Valid clues generated on attempt {attempt}\")\n",
    "            else:\n",
    "                print(f\"    ‚ùå Invalid clues: {len(failed_clues)}/{total_clues} failed (e.g., {failed_clues[:2]}). Retrying...\")\n",
    "        else:\n",
    "            print(f\"    ‚ùå No valid JSON on attempt {attempt}\")\n",
    "        \n",
    "        sleep(5)  # Increased from 5 to 10 seconds for rate limiting\n",
    "    \n",
    "    if valid_data:\n",
    "        try:\n",
    "            all_rows.extend(process_game_data(valid_data, topic, run_number))\n",
    "            print(f\"‚úÖ Test {run_number} completed successfully after {attempt} attempts\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing data for test {run_number}: {e}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Test {run_number} failed after {max_retries} attempts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6HdR9_0Ht1y",
    "outputId": "d5285434-a3c2-4fab-9c88-672d0a3d7c29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CSV saved: 10_rounds_clues_analysis.csv\n",
      "Total rows generated: 280\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "with open(\"10_rounds_clues_analysis.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    if all_rows:\n",
    "        writer = csv.DictWriter(f, fieldnames=all_rows[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_rows)\n",
    "        print(f\"‚úÖ CSV saved: 10_rounds_clues_analysis.csv\")\n",
    "\n",
    "print(f\"Total rows generated: {len(all_rows)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1A0fc3WdZymW"
   },
   "source": [
    "## LLM analysis (llama)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixZR4gtyhwU-"
   },
   "outputs": [],
   "source": [
    "analysis_model = init_chat_model(\n",
    "    # model=\"llama-3.3-70b-versatile\",\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    model_provider=\"groq\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_OurpVJ2h9eD"
   },
   "outputs": [],
   "source": [
    "def analyze_round_with_llm(round_data, analysis_model):\n",
    "    \"\"\"Analyze a single round using LLM\"\"\"\n",
    "\n",
    "    # Count words for each clue type\n",
    "    word_counts = {}\n",
    "    length_issues = []\n",
    "\n",
    "    for clue_type in [\"informed_clues\", \"misinformed_clues\", \"fake_clues\", \"extra_clues\"]:\n",
    "        clues = round_data.get(clue_type, [])\n",
    "        word_counts[clue_type] = []\n",
    "\n",
    "        for i, clue in enumerate(clues, 1):\n",
    "            word_count = len(clue.split())\n",
    "            word_counts[clue_type].append(word_count)\n",
    "\n",
    "            if not (15 <= word_count <= 20):\n",
    "                length_issues.append(f\"{clue_type} #{i}: {word_count} words\")\n",
    "\n",
    "    # Create word count summary\n",
    "    word_count_summary = f\"\"\"\n",
    "WORD COUNT ANALYSIS:\n",
    "- Informed clues: {word_counts.get('informed_clues', [])}\n",
    "- Misinformed clues: {word_counts.get('misinformed_clues', [])}\n",
    "- Fake clues: {word_counts.get('fake_clues', [])}\n",
    "- Extra clues: {word_counts.get('extra_clues', [])}\n",
    "\n",
    "LENGTH ISSUES (should be 15-20 words):\n",
    "{'; '.join(length_issues) if length_issues else 'All clues meet length requirements'}\n",
    "\"\"\"\n",
    "\n",
    "    analysis_prompt = f\"\"\"\n",
    "You are evaluating clues for a deduction game. Analyze BOTH word count compliance AND content quality.\n",
    "\n",
    "{word_count_summary}\n",
    "\n",
    "ROUND DATA:\n",
    "{json.dumps(round_data, indent=2)}\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "1. LENGTH COMPLIANCE: Each clue should be 15-20 words (see analysis above)\n",
    "2. ANSWER CONTAMINATION: Check if ANY clue contains the answer word\n",
    "3. SPECIFICITY: Are clues specific enough to distinguish from similar items?\n",
    "4. CLUE REFERENCES: Use specific clue numbers when noting issues\n",
    "5. DETAILED REASONING: Explain WHY you gave each score\n",
    "\n",
    "CLUE TYPE REQUIREMENTS:\n",
    "- **INFORMED CLUES**: Must relate to actual answer and be distinct/specific (avoid generic descriptions)\n",
    "- **MISINFORMED CLUES**: Must be related to actual answer BUT vague enough to apply to multiple choices (create productive doubt)\n",
    "- **FAKE CLUES**: Must clearly point to the OTHER answer choices, NOT the correct answer (effective misdirection)\n",
    "\n",
    "SCORING SCALE (MANDATORY):\n",
    "Rate based on how well each clue type fulfills its specific purpose:\n",
    "- informed_quality: Rate 1-5 (How well do they point to correct answer specifically?)\n",
    "- misinformed_quality: Rate 1-5 (Do they create ambiguity while staying answer-related?)\n",
    "- fake_quality: Rate 1-5 (Do they clearly misdirect to wrong answer choices?)\n",
    "- difficulty: Rate 1-5 (1=too easy, 2=easy, 3=just right, 4=hard, 5=too hard)\n",
    "\n",
    "Return ONLY this JSON format:\n",
    "{{\n",
    "  \"length_compliance_score\": number (1-5),\n",
    "  \"length_issues_found\": [\"list of specific length problems\"],\n",
    "  \"informed_quality\": number (1-5),\n",
    "  \"informed_notes\": \"detailed analysis with specific clue numbers\",\n",
    "  \"misinformed_quality\": number (1-5),\n",
    "  \"misinformed_notes\": \"detailed analysis of ambiguity effectiveness\",\n",
    "  \"fake_quality\": number (1-5),\n",
    "  \"fake_notes\": \"detailed analysis of misdirection effectiveness\",\n",
    "  \"diversity_issues\": [\"list specific problems found\"],\n",
    "  \"difficulty\": number (1-5),\n",
    "  \"difficulty_reasoning\": \"detailed explanation\",\n",
    "  \"overall_notes\": \"comprehensive summary\"\n",
    "}}\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = analysis_model.invoke([HumanMessage(analysis_prompt)])\n",
    "        update_token_usage(response)\n",
    "        return extract_json_from_response(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå LLM analysis failed: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdYVHNS9lv5r"
   },
   "outputs": [],
   "source": [
    "# Load data from your manual analysis CSV\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file from your manual analysis\n",
    "df = pd.read_csv(\"10_rounds_clues_analysis.csv\")  # Change filename as needed\n",
    "\n",
    "# Group data by test_run and round to reconstruct round_data\n",
    "all_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ex9epMELiCFt",
    "outputId": "3acb14c5-49db-47e6-e947-a335d1e1b0ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Test 1, Round 1: Movie - movie\n",
      "  ‚úÖ Analyzed successfully\n",
      "Analyzing Test 1, Round 2: Movie - Star Wars Episode I: The Phantom Menace\n",
      "  ‚ùå Analysis failed\n",
      "Analyzing Test 2, Round 1: Song - song\n",
      "  ‚ùå Analysis failed\n",
      "Analyzing Test 2, Round 2: Song - Bohemian Rhapsody\n",
      "  ‚úÖ Analyzed successfully\n",
      "Analyzing Test 3, Round 1: Book - book\n",
      "  ‚úÖ Analyzed successfully\n",
      "Analyzing Test 3, Round 2: Book - Harry Potter and the Sorcerer's Stone\n",
      "  ‚ùå Analysis failed\n",
      "Analyzing Test 4, Round 1: TV Show - TV Show\n",
      "  ‚ùå Analysis failed\n",
      "Analyzing Test 4, Round 2: TV Show - Breaking Bad\n",
      "  ‚úÖ Analyzed successfully\n",
      "Analyzing Test 5, Round 1: Video Game - video game\n",
      "  ‚ùå Analysis failed\n",
      "Analyzing Test 5, Round 2: Video Game - The Legend of Zelda: Breath of the Wild\n",
      "  ‚úÖ Analyzed successfully\n",
      "Analyzing Test 6, Round 1: Food - food\n",
      "  ‚ùå Analysis failed\n",
      "Analyzing Test 6, Round 2: Food - Pizza Margherita\n",
      "  ‚úÖ Analyzed successfully\n",
      "Analyzing Test 7, Round 1: Animal - Animal\n",
      "  ‚ùå Analysis failed\n",
      "Analyzing Test 7, Round 2: Animal - African Elephant\n",
      "‚ùå LLM analysis failed: Connection error.\n",
      "  ‚ùå Analysis failed\n",
      "Analyzing Test 8, Round 1: Sport - sport\n",
      "‚ùå LLM analysis failed: Connection error.\n",
      "  ‚ùå Analysis failed\n",
      "Analyzing Test 8, Round 2: Sport - Tennis\n",
      "‚ùå LLM analysis failed: Connection error.\n",
      "  ‚ùå Analysis failed\n",
      "Analyzing Test 9, Round 1: Country - Country\n",
      "‚ùå LLM analysis failed: Connection error.\n",
      "  ‚ùå Analysis failed\n",
      "Analyzing Test 9, Round 2: Country - Japan\n",
      "‚ùå LLM analysis failed: Connection error.\n",
      "  ‚ùå Analysis failed\n",
      "Analyzing Test 10, Round 1: Historical Event - Historical Event\n",
      "‚ùå LLM analysis failed: Connection error.\n",
      "  ‚ùå Analysis failed\n",
      "Analyzing Test 10, Round 2: Historical Event - Moon Landing 1969\n",
      "‚ùå LLM analysis failed: Connection error.\n",
      "  ‚ùå Analysis failed\n"
     ]
    }
   ],
   "source": [
    "for (test_run, round_num), group in df.groupby(['test_run', 'round']):\n",
    "    # Skip disinformer instructions\n",
    "    clue_data = group[group['clue_type'] != 'disinformer_instruction']\n",
    "\n",
    "    if len(clue_data) == 0:\n",
    "        continue\n",
    "\n",
    "    # Get basic info\n",
    "    topic_category = clue_data['topic_category'].iloc[0]\n",
    "    topic_specific = clue_data['topic_specific'].iloc[0]\n",
    "    answer = clue_data['answer'].iloc[0]\n",
    "    choices = clue_data['choices'].iloc[0]\n",
    "\n",
    "    print(f\"Analyzing Test {test_run}, Round {round_num}: {topic_category} - {answer}\")\n",
    "\n",
    "    # Reconstruct round_data from CSV\n",
    "    round_data = {\n",
    "        \"answer\": answer,\n",
    "        \"choices\": choices.split(\" | \") if choices else [],\n",
    "        \"informed_clues\": clue_data[clue_data['clue_type'] == 'informed']['clue_text'].tolist(),\n",
    "        \"misinformed_clues\": clue_data[clue_data['clue_type'] == 'misinformed']['clue_text'].tolist(),\n",
    "        \"fake_clues\": clue_data[clue_data['clue_type'] == 'fake']['clue_text'].tolist(),\n",
    "        \"extra_clues\": clue_data[clue_data['clue_type'] == 'extra']['clue_text'].tolist()\n",
    "    }\n",
    "\n",
    "    # Analyze with LLM\n",
    "    analysis = analyze_round_with_llm(round_data, analysis_model)\n",
    "\n",
    "    if analysis:\n",
    "        result = {\n",
    "            \"test_run\": test_run,\n",
    "            \"topic_category\": topic_category,\n",
    "            \"topic_specific\": topic_specific,\n",
    "            \"round\": round_num,\n",
    "            \"answer\": answer,\n",
    "            \"choices\": choices,\n",
    "\n",
    "            # LLM Analysis Results\n",
    "            \"informed_quality\": analysis.get(\"informed_quality\", \"\"),\n",
    "            \"informed_notes\": analysis.get(\"informed_notes\", \"\"),\n",
    "            \"misinformed_quality\": analysis.get(\"misinformed_quality\", \"\"),\n",
    "            \"misinformed_notes\": analysis.get(\"misinformed_notes\", \"\"),\n",
    "            \"fake_quality\": analysis.get(\"fake_quality\", \"\"),\n",
    "            \"fake_notes\": analysis.get(\"fake_notes\", \"\"),\n",
    "            \"diversity_issues\": \"; \".join(analysis.get(\"diversity_issues\", [])),\n",
    "            \"difficulty\": analysis.get(\"difficulty\", \"\"),\n",
    "            \"difficulty_reasoning\": analysis.get(\"difficulty_reasoning\", \"\"),\n",
    "            \"overall_notes\": analysis.get(\"overall_notes\", \"\"),\n",
    "\n",
    "            # Word count and length compliance data\n",
    "            \"total_clues\": len(round_data[\"informed_clues\"]) + len(round_data[\"misinformed_clues\"]) + len(round_data[\"fake_clues\"]) + len(round_data[\"extra_clues\"]),\n",
    "            \"length_compliant_clues\": sum(1 for clue_type in [\"informed_clues\", \"misinformed_clues\", \"fake_clues\", \"extra_clues\"]\n",
    "                                        for clue in round_data[clue_type]\n",
    "                                        if 15 <= len(clue.split()) <= 20),\n",
    "            \"length_compliance_rate\": f\"{(sum(1 for clue_type in ['informed_clues', 'misinformed_clues', 'fake_clues', 'extra_clues'] for clue in round_data[clue_type] if 15 <= len(clue.split()) <= 20) / max(1, sum(len(round_data[clue_type]) for clue_type in ['informed_clues', 'misinformed_clues', 'fake_clues', 'extra_clues'])) * 100):.0f}%\",\n",
    "            \"avg_word_count\": round(sum(len(clue.split()) for clue_type in [\"informed_clues\", \"misinformed_clues\", \"fake_clues\", \"extra_clues\"] for clue in round_data[clue_type]) / max(1, sum(len(round_data[clue_type]) for clue_type in [\"informed_clues\", \"misinformed_clues\", \"fake_clues\", \"extra_clues\"])), 1)\n",
    "        }\n",
    "\n",
    "        all_results.append(result)\n",
    "        print(f\"  ‚úÖ Analyzed successfully\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå Analysis failed\")\n",
    "\n",
    "    sleep(5)  # Increased from 2 to 5 seconds for rate limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xayzwc_0iO-L",
    "outputId": "f1735cba-482e-4fec-c580-03c4e264fb10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM analysis complete! Saved 6 results to: llm_analysis_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "if all_results:\n",
    "    with open(\"llm_analysis_results.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=all_results[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_results)\n",
    "\n",
    "    print(f\"‚úÖ LLM analysis complete! Saved {len(all_results)} results to: llm_analysis_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Generated analysis matrices for Test 1: clue_analysis_matrices\\test1_clue_analysis.md\n",
      "‚úÖ Generated analysis matrices for Test 2: clue_analysis_matrices\\test2_clue_analysis.md\n",
      "‚úÖ Generated analysis matrices for Test 3: clue_analysis_matrices\\test3_clue_analysis.md\n",
      "‚úÖ Generated analysis matrices for Test 4: clue_analysis_matrices\\test4_clue_analysis.md\n",
      "‚úÖ Generated analysis matrices for Test 5: clue_analysis_matrices\\test5_clue_analysis.md\n",
      "‚úÖ Generated analysis matrices for Test 6: clue_analysis_matrices\\test6_clue_analysis.md\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'tabulate'.  Use pip or conda to install tabulate.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\compat\\_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tabulate'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 215\u001b[0m\n\u001b[0;32m    207\u001b[0m overall_summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Overall Performance Breakdown by Category\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    208\u001b[0m by_category \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic_category\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg({\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_compliance_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(x\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39mmean())\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minformed_quality\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifficulty\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    214\u001b[0m })\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m--> 215\u001b[0m overall_summary \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mby_category\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;66;03m# Save overall summary to a markdown file\u001b[39;00m\n\u001b[0;32m    218\u001b[0m overall_file \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDisinformer_Game_Clues_Quality_Summary.MD\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:2983\u001b[0m, in \u001b[0;36mDataFrame.to_markdown\u001b[1;34m(self, buf, mode, index, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m   2981\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtablefmt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2982\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshowindex\u001b[39m\u001b[38;5;124m\"\u001b[39m, index)\n\u001b[1;32m-> 2983\u001b[0m tabulate \u001b[38;5;241m=\u001b[39m \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtabulate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2984\u001b[0m result \u001b[38;5;241m=\u001b[39m tabulate\u001b[38;5;241m.\u001b[39mtabulate(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Vincent\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\compat\\_optional.py:138\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 138\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'tabulate'.  Use pip or conda to install tabulate."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure the utility functions below exist in your notebook cell.\n",
    "def calculate_length_compliance(row):\n",
    "    compliance_rate = int(row['length_compliance_rate'].rstrip('%'))\n",
    "    total_clues = row['total_clues']\n",
    "    compliant = row['length_compliant_clues']\n",
    "    non_compliant = total_clues - compliant\n",
    "    return compliance_rate, compliant, non_compliant, total_clues\n",
    "\n",
    "def get_pass_fail_status(compliance_rate):\n",
    "    return \"‚úÖ PASS\" if compliance_rate >= 80 else \"‚ùå FAIL\"\n",
    "\n",
    "def get_quality_assessment(score):\n",
    "    assessments = {\n",
    "        1: \"Poor - Needs significant revision\",\n",
    "        2: \"Fair - Below expectations\",\n",
    "        3: \"Good - Meets requirements\",\n",
    "        4: \"Very Good - Exceeds expectations\",\n",
    "        5: \"Excellent - Outstanding\"\n",
    "    }\n",
    "    return assessments.get(int(score), \"Unknown\")\n",
    "\n",
    "def get_difficulty_assessment(difficulty):\n",
    "    difficulty = int(difficulty)\n",
    "    if difficulty <= 2:\n",
    "        return \"üü¢ Too Easy\"\n",
    "    elif difficulty == 3:\n",
    "        return \"üü¢ Just Right\"\n",
    "    else:\n",
    "        return \"üü† Too Hard\"\n",
    "\n",
    "def extract_issues(notes_str):\n",
    "    import pandas as pd\n",
    "    if pd.isna(notes_str):\n",
    "        return [\"None identified\"]\n",
    "    notes_str = str(notes_str).lower()\n",
    "    issues = []\n",
    "    keywords = {\n",
    "        \"length\": \"Word count compliance issues\",\n",
    "        \"generic\": \"Generic/vague clues\",\n",
    "        \"diversity\": \"Lack of diversity in themes\",\n",
    "        \"ambiguity\": \"Insufficient ambiguity in misinformed clues\",\n",
    "        \"specificity\": \"Missing specificity in clues\",\n",
    "        \"answer contamination\": \"Answer word revealed in clues\"\n",
    "    }\n",
    "    for keyword, issue in keywords.items():\n",
    "        if keyword in notes_str:\n",
    "            issues.append(issue)\n",
    "    return issues if issues else [\"Minor issues noted\"]\n",
    "\n",
    "def generate_matrix_for_round(row):\n",
    "    test_run = int(row['test_run'])\n",
    "    topic_cat = row['topic_category']\n",
    "    topic_spec = row['topic_specific']\n",
    "    round_num = int(row['round'])\n",
    "    compliance_rate, compliant, non_compliant, total = calculate_length_compliance(row)\n",
    "    status = get_pass_fail_status(compliance_rate)\n",
    "    informed_score = int(row['informed_quality'])\n",
    "    misinformed_score = int(row['misinformed_quality'])\n",
    "    fake_score = int(row['fake_quality'])\n",
    "    difficulty = int(row['difficulty'])\n",
    "    issues = extract_issues(row['overall_notes'])\n",
    "    diversity_issues = row['diversity_issues'] if not pd.isna(row['diversity_issues']) else \"None identified\"\n",
    "    \n",
    "    matrix = f\"\"\"# Game Clue Analysis Matrix\n",
    "**Test Run {test_run} | Round {round_num}: {topic_cat} ‚Üí {topic_spec}**\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Length Compliance\n",
    "| Status | Criteria |\n",
    "|--------|----------|\n",
    "| {status} | Clues within 15-20 words |\n",
    "\n",
    "**Compliance Rate:** {compliance_rate}% ({compliant}/{total} clues)  \n",
    "**Outliers:** {non_compliant}/{total} clues failed  \n",
    "**Average Word Count:** {row['avg_word_count']} words\n",
    "\n",
    "**Assessment:** {\"‚úÖ Acceptable - Most clues meet length requirements\" if compliance_rate >= 80 else \"‚ùå Critical - Significant length violations require revision\"}\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Quality Scores (Rate 1-5)\n",
    "\n",
    "### Informed Clues: {informed_score}/5  \n",
    "**{get_quality_assessment(informed_score)}**\n",
    "\n",
    "{row['informed_notes']}\n",
    "\n",
    "‚úÖ Strengths:\n",
    "- Generally specific and relate to correct answer\n",
    "- Provide distinct perspectives where applicable\n",
    "\n",
    "‚ö†Ô∏è Concerns:\n",
    "- {row['diversity_issues'] if not pd.isna(row['diversity_issues']) else \"Minor thematic overlap observed\"}\n",
    "\n",
    "### Misinformed Clues: {misinformed_score}/5  \n",
    "**{get_quality_assessment(misinformed_score)}**\n",
    "\n",
    "{row['misinformed_notes']}\n",
    "\n",
    "‚úÖ Strengths:\n",
    "- Attempt to create ambiguity\n",
    "- Generally related to the correct answer\n",
    "\n",
    "‚ö†Ô∏è Concerns:\n",
    "- May need more subtle misdirection\n",
    "- Ambiguity effectiveness varies\n",
    "\n",
    "### Fake Clues: {fake_score}/5  \n",
    "**{get_quality_assessment(fake_score)}**\n",
    "\n",
    "{row['fake_notes']}\n",
    "\n",
    "‚úÖ Strengths:\n",
    "- Effectively misdirect to wrong answer choices\n",
    "- Clear deception without being obvious\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Diversity Check\n",
    "\n",
    "| Aspect | Status |\n",
    "|--------|--------|\n",
    "| Theme Coverage | {\"‚úÖ PASS\" if \"diversity\" not in diversity_issues.lower() else \"‚ùå FAIL\"} |\n",
    "| Clue Variation | {\"‚úÖ PASS\" if informed_score >= 3 else \"‚ùå FAIL\"} |\n",
    "| Angle Coverage | {\"‚úÖ PASS\" if non_compliant <= 2 else \"‚ùå FAIL\"} |\n",
    "\n",
    "**Issues Found:** {diversity_issues}\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Difficulty Rating\n",
    "\n",
    "| Score | Assessment |\n",
    "|-------|------------|\n",
    "| Rating | {difficulty}/5 - {get_difficulty_assessment(difficulty)} |\n",
    "\n",
    "**Reasoning:** {row['difficulty_reasoning']}\n",
    "\n",
    "---\n",
    "\n",
    "## Overall Assessment\n",
    "\n",
    "**Overall Quality Score:** {(informed_score + misinformed_score + fake_score) / 3:.1f}/5\n",
    "\n",
    "**Pass/Fail:** {\"‚úÖ PASS\" if compliance_rate >= 70 and (informed_score + misinformed_score + fake_score) / 3 >= 3 else \"‚ö†Ô∏è NEEDS REVISION\"}\n",
    "\n",
    "**Main Issues:**\n",
    "{chr(10).join(f\"- {issue}\" for issue in issues)}\n",
    "\n",
    "**Priority Actions:**\n",
    "1. {\"Address length compliance\" if compliance_rate < 80 else \"Minor length adjustments\"}\n",
    "2. {\"Enhance misinformed clue ambiguity\" if misinformed_score < 3 else \"Maintain misinformed clue quality\"}\n",
    "3. {\"Increase clue diversity\" if \"diversity\" in diversity_issues.lower() else \"Maintain current diversity\"}\n",
    "\n",
    "**Overall Notes:**  \n",
    "{row['overall_notes']}\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "    return matrix\n",
    "\n",
    "# --- Matrices Generation per Test Run ---\n",
    "csv_path = Path(\"llm_analysis_results.csv\")\n",
    "if not csv_path.exists():\n",
    "    print(f\"‚ùå Error: {csv_path} not found.\")\n",
    "else:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    test_runs = df['test_run'].unique()\n",
    "    dir = Path(\"clue_analysis_matrices\")\n",
    "    dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    for test in sorted(test_runs):\n",
    "        group = df[df['test_run'] == test]\n",
    "        text = f\"# Analysis for Test {test}\\n\\n\"\n",
    "        \n",
    "        # Append matrices for each round in the test\n",
    "        rounds = sorted(group['round'].unique())\n",
    "        for r in rounds:\n",
    "            row = group[group['round'] == r].iloc[0]\n",
    "            matrix_text = generate_matrix_for_round(row)\n",
    "            text += matrix_text + \"\\n\\n\"\n",
    "        \n",
    "        # Append a round-by-round performance summary table for this test\n",
    "        text += \"## Round-by-Round Performance Summary\\n\\n\"\n",
    "        text += \"| Round | Length Compliance | Informed | Misinformed | Fake | Difficulty |\\n\"\n",
    "        text += \"|-------|-------------------|----------|-------------|------|------------|\\n\"\n",
    "        for r in rounds:\n",
    "            row = group[group['round'] == r].iloc[0]\n",
    "            length_comp = row['length_compliance_rate']\n",
    "            inf_score = row['informed_quality']\n",
    "            mis_score = row['misinformed_quality']\n",
    "            fake_score = row['fake_quality']\n",
    "            difficulty = row['difficulty']\n",
    "            text += f\"| {r} | {length_comp} | {inf_score}/5 | {mis_score}/5 | {fake_score}/5 | {difficulty}/5 |\\n\"\n",
    "        \n",
    "        # Save markdown for this test run\n",
    "        test_file = dir / f\"test{test}_clue_analysis.md\"\n",
    "        with open(test_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(text)\n",
    "        print(f\"‚úÖ Generated analysis matrices for Test {test}: {test_file}\")\n",
    "    \n",
    "    # --- Overall Performance Breakdown by Category ---\n",
    "    overall_summary = \"# Overall Performance Breakdown by Category\\n\\n\"\n",
    "    by_category = df.groupby('topic_category').agg({\n",
    "        'length_compliance_rate': lambda x: f\"{int(x.str.rstrip('%').astype(int).mean()):.0f}%\",\n",
    "        'informed_quality': lambda x: f\"{x.astype(int).mean():.1f}/5\",\n",
    "        'misinformed_quality': lambda x: f\"{x.astype(int).mean():.1f}/5\",\n",
    "        'fake_quality': lambda x: f\"{x.astype(int).mean():.1f}/5\",\n",
    "        'difficulty': lambda x: f\"{x.astype(int).mean():.1f}/5\"\n",
    "    }).reset_index()\n",
    "    overall_summary += by_category.to_markdown(index=False)\n",
    "    \n",
    "    # Save overall summary to a markdown file\n",
    "    overall_file = Path(\"Disinformer_Game_Clues_Quality_Summary.MD\")\n",
    "    with open(overall_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(overall_summary)\n",
    "    print(f\"‚úÖ Overall performance by category saved: {overall_file}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
